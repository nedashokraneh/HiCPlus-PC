{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'torch'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-6925ab583355>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mgzip\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/HiCPlus_pytorch/src/model.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mVariable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunctional\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'torch'"
     ]
    }
   ],
   "source": [
    "#libraries\n",
    "import sys\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "import os\n",
    "import gzip\n",
    "import model\n",
    "from torch.utils import data\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "from time import gmtime, strftime\n",
    "import sys\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#variables\n",
    "use_gpu = 0\n",
    "conv2d1_filters_numbers = 8\n",
    "conv2d1_filters_size = 9\n",
    "conv2d2_filters_numbers = 8\n",
    "conv2d2_filters_size = 1\n",
    "conv2d3_filters_numbers = 1\n",
    "conv2d3_filters_size = 5\n",
    "down_sample_ratio = 16\n",
    "epochs = 50\n",
    "HiC_max_value = 100 # ?????\n",
    "batch_size = 256\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#loading data\n",
    "low_resolution_samples = np.load(\"../data/divided-data/GM12878_primary_down_chr1-17.npy\").astype(np.float32) * down_sample_ratio\n",
    "low_resolution_samples = np.expand_dims(low_resolution_samples, axis=1)\n",
    "high_resolution_samples = np.load(\"../data/divided-data/GM12878_primary_chr1-17.npy\").astype(np.float32)\n",
    "high_resolution_samples = np.expand_dims(high_resolution_samples, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#changing high resolution data size\n",
    "sample_size = low_resolution_samples.shape[-1]\n",
    "padding = conv2d1_filters_size + conv2d2_filters_size + conv2d3_filters_size - 3\n",
    "half_padding = padding / 2\n",
    "high_resolution_samples = high_resolution_samples[:,:,half_padding:(sample_size-half_padding),half_padding:(sample_size-half_padding)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#loading data to tensor\n",
    "# still not getting why np.zeros has been added\n",
    "lowres_set = data.TensorDataset(torch.from_numpy(low_resolution_samples), torch.from_numpy(np.zeros(low_resolution_samples.shape[0])))\n",
    "lowres_loader = torch.utils.data.DataLoader(lowres_set, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "hires_set = data.TensorDataset(torch.from_numpy(high_resolution_samples), torch.from_numpy(np.zeros(high_resolution_samples.shape[0])))\n",
    "hires_loader = torch.utils.data.DataLoader(hires_set, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#defining model\n",
    "Net = model.Net(40, 28)\n",
    "if use_gpu:\n",
    "    Net = Net.cuda()\n",
    "\n",
    "optimizer = optim.SGD(Net.parameters(), lr = 0.00001)\n",
    "_loss = nn.MSELoss()\n",
    "Net.train()\n",
    "running_loss = 0.0\n",
    "losslist = []\n",
    "log = open('HindIII_train.txt', 'w')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#training model\n",
    "for epoch in range(0, epochs):\n",
    "    # iterate over two lists and their indices using enumerate together with zip\n",
    "    # lowres_loader is list of batches\n",
    "    for i, (v1, v2) in enumerate(zip(lowres_loader, hires_loader)):\n",
    "        # probably it is for skipping last incomplete batch\n",
    "        if (i == len(lowres_loader) - 1):\n",
    "            continue\n",
    "\n",
    "\n",
    "        # v1 is list with length = 2. v1[0] is data tensor so with shape 256*1*40*40. v1[1] is vector of 256 zeros because pf line 85 but what's the reason?\n",
    "        _lowRes, _ = v1\n",
    "        _highRes, _ = v2\n",
    "        # print \"_lowres:\", _lowRes, \"\\n shape: \", _lowRes.shape\n",
    "\n",
    "        _lowRes = Variable(_lowRes)\n",
    "        _highRes = Variable(_highRes)\n",
    "\n",
    "\n",
    "        if use_gpu:\n",
    "            _lowRes = _lowRes.cuda()\n",
    "            _highRes = _highRes.cuda()\n",
    "        optimizer.zero_grad()\n",
    "        y_prediction = Net(_lowRes)\n",
    "        loss = _loss(y_prediction, _highRes)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        #print(loss.item())\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    print '-------', i, epoch, running_loss/i, strftime(\"%Y-%m-%d %H:%M:%S\", gmtime())\n",
    "    losslist.append(running_loss/i)\n",
    "    log.write(str(epoch) + ', ' + str(running_loss/i,) + '\\n')\n",
    "    running_loss = 0.0\n",
    "    # save the model every 10 epoches\n",
    "    if (epoch % 10 == 0):\n",
    "        if not os.path.exists('../models/19-06-05/'):\n",
    "            os.makedirs('../models/19-06-05/')\n",
    "        torch.save(Net.state_dict(), '../models/19-06-05/' + str(epoch))\n",
    "        pass\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(test_cor_list, label = \"test_cor\")\n",
    "plt.plot(train_cor_list, label = \"train_cor\")\n",
    "#plt.axis([0, 6, 0, 20])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_y_prediction = Net(torch.from_numpy(test_low_resolution_samples)).detach().numpy()\n",
    "    train_y_prediction = Net(torch.from_numpy(train_low_resolution_samples)).detach().numpy()\n",
    "    ### evaluating part ###\n",
    "    test_cor = np.nanmean([corr_highVSlow(i,test_y_prediction,test_high_resolution_samples) for i in range(test_low_resolution_samples.shape[0])])\n",
    "    train_cor = np.nanmean([corr_highVSlow(i,train_y_prediction,train_high_resolution_samples) for i in range(train_low_resolution_samples.shape[0])])\n",
    "    print(\"test data correlation: \", test_cor)\n",
    "    print(\"train data correlation: \", train_cor)\n",
    "    test_cor_list.append(test_cor)\n",
    "    train_cor_list.append(train_cor)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
